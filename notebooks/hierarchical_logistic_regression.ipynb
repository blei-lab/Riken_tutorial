{
 "metadata": {
  "name": "",
  "signature": "sha256:56f2a5c6da2bc4def0273c7fdef06b9c6996d73b779619c7c34b2f770c7510cc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Logistic Regression\n",
      "\n",
      "Now let's assume the response variable is binary. Then rather than having a `Normal` likelihood, the `Bernoulli` distribution is more appropriate. This is easy to change in Edward."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"Hierarchical logistic regression using variational inference.\n",
      "\"\"\"\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "import edward as ed\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "\n",
      "from edward.models import Normal, Bernoulli\n",
      "from edward.stats import bernoulli, norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_toy_dataset(N, noise_std=0.1):\n",
      "    D = 1\n",
      "    x = np.linspace(-6, 6, num=N)\n",
      "    y = np.tanh(x) + np.random.normal(0, noise_std, size=N)\n",
      "    y[y < 0.5] = 0\n",
      "    y[y >= 0.5] = 1\n",
      "    x = (x - 4.0) / 4.0\n",
      "    x = x.reshape((N, D))\n",
      "    return x, y\n",
      "\n",
      "\n",
      "ed.set_seed(42)\n",
      "\n",
      "N = 40  # number of data points\n",
      "D = 1  # number of features\n",
      "\n",
      "x_train, y_train = build_toy_dataset(N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise \n",
      "Now the likelihood is Bernoulli, rather than Normal. Below, parameterize the logits with the other model variables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = tf.placeholder(tf.float32, [N, D])\n",
      "w = Normal(mu=tf.zeros(D), sigma=3.0 * tf.ones(D))\n",
      "b = Normal(mu=tf.zeros([]), sigma=3.0 * tf.ones([]))\n",
      "y = Bernoulli(logits=?)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "Let's define the variational parameters and then the variational distribution. Let's use Gaussians."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "qw_mu = tf.Variable(tf.random_normal([D]))\n",
      "qw_sigma = tf.nn.softplus(tf.Variable(tf.random_normal([D])))\n",
      "qb_mu = tf.Variable(tf.random_normal([]) + 10)\n",
      "qb_sigma = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
      "\n",
      "qw = ?\n",
      "qb = ?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "Can you tie each model variable to the appropriate variational factor?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = {x: x_train, y: y_train}\n",
      "model_factors = {?}\n",
      "inference = ed.KLqp(model_factors, data)\n",
      "\n",
      "inference.initialize(n_print=10, n_iter=600)\n",
      "tf.global_variables_initializer().run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "We want to sample from the variational distribution. Can you fill in the question marks below?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# draws from variational distribution\n",
      "S = 50\n",
      "rs = np.random.RandomState(0)\n",
      "inputs = np.linspace(-5, 3, num=400, dtype=np.float32)\n",
      "x_in = tf.expand_dims(inputs, 1)\n",
      "mus = []\n",
      "for s in range(S):\n",
      "    mus += [tf.sigmoid(ed.dot(x_in, ?) + ?)]\n",
      "mus = tf.stack(mus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up figure\n",
      "fig = plt.figure(figsize=(8, 8), facecolor='white')\n",
      "ax = fig.add_subplot(111, frameon=False)\n",
      "plt.ion()\n",
      "plt.show(block=False)\n",
      "\n",
      "\n",
      "for t in range(inference.n_iter):\n",
      "    info_dict = inference.update()\n",
      "    inference.print_progress(info_dict)\n",
      "\n",
      "    if t % inference.n_print == 0:\n",
      "        outputs = mus.eval()\n",
      "\n",
      "        # Plot data and functions\n",
      "        plt.cla()\n",
      "        ax.plot(x_train[:], y_train, 'bx')\n",
      "        for s in range(S):\n",
      "            ax.plot(inputs, outputs[s], alpha=0.2)\n",
      "        ax.set_xlim([-5, 3])\n",
      "        ax.set_ylim([-0.5, 1.5])\n",
      "        plt.draw()\n",
      "        plt.pause(1.0 / 60.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration   1 [  0%]: Loss = 226.213\n",
        "Iteration  10 [  1%]: Loss = 183.075"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  20 [  3%]: Loss = 170.514"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  30 [  5%]: Loss = 31.371"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  40 [  6%]: Loss = 36.543"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  50 [  8%]: Loss = 21.003"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  60 [ 10%]: Loss = 10.695"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  70 [ 11%]: Loss = 12.115"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  80 [ 13%]: Loss = 9.819"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  90 [ 15%]: Loss = 12.528"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 100 [ 16%]: Loss = 8.632"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 110 [ 18%]: Loss = 7.938"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 120 [ 20%]: Loss = 9.169"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 130 [ 21%]: Loss = 8.580"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 140 [ 23%]: Loss = 8.548"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 150 [ 25%]: Loss = 8.401"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 160 [ 26%]: Loss = 9.211"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 170 [ 28%]: Loss = 10.538"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 180 [ 30%]: Loss = 9.375"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 190 [ 31%]: Loss = 8.905"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 200 [ 33%]: Loss = 9.331"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 210 [ 35%]: Loss = 12.388"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 220 [ 36%]: Loss = 8.332"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 230 [ 38%]: Loss = 9.842"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 240 [ 40%]: Loss = 10.997"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 250 [ 41%]: Loss = 10.811"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 260 [ 43%]: Loss = 11.087"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 270 [ 45%]: Loss = 10.653"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 280 [ 46%]: Loss = 9.808"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 290 [ 48%]: Loss = 12.158"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 300 [ 50%]: Loss = 10.176"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 310 [ 51%]: Loss = 9.749"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 320 [ 53%]: Loss = 10.867"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 330 [ 55%]: Loss = 10.988"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 340 [ 56%]: Loss = 9.521"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 350 [ 58%]: Loss = 8.866"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 360 [ 60%]: Loss = 8.923"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 370 [ 61%]: Loss = 9.406"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 380 [ 63%]: Loss = 9.107"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 390 [ 65%]: Loss = 9.243"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 400 [ 66%]: Loss = 11.699"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 410 [ 68%]: Loss = 12.216"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 420 [ 70%]: Loss = 9.192"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 430 [ 71%]: Loss = 10.579"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 440 [ 73%]: Loss = 13.030"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 450 [ 75%]: Loss = 11.708"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 460 [ 76%]: Loss = 8.890"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 470 [ 78%]: Loss = 10.600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 480 [ 80%]: Loss = 9.606"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 490 [ 81%]: Loss = 8.850"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 500 [ 83%]: Loss = 8.492"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 510 [ 85%]: Loss = 8.360"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 520 [ 86%]: Loss = 9.506"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 530 [ 88%]: Loss = 11.627"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 540 [ 90%]: Loss = 8.779"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 550 [ 91%]: Loss = 8.610"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 560 [ 93%]: Loss = 8.491"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 570 [ 95%]: Loss = 9.897"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 580 [ 96%]: Loss = 9.802"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 590 [ 98%]: Loss = 8.436"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 600 [100%]: Loss = 21.380"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}